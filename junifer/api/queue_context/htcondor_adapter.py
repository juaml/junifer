"""Define concrete class for generating HTCondor assets."""

# Authors: Synchon Mandal <s.mandal@fz-juelich.de>
# License: AGPL

import shutil
import textwrap
from enum import Enum
from pathlib import Path
from typing import Any, Optional

from ...typing import Elements
from ...utils import logger, make_executable, run_ext_cmd
from .queue_context_adapter import (
    EnvKind,
    EnvShell,
    QueueContextAdapter,
    QueueContextEnv,
)


__all__ = ["HTCondorAdapter", "HTCondorCollect"]


class HTCondorCollect(str, Enum):
    """Accepted HTCondor collect commands.

    * ``"yes"``: Submit "collect" task and run even if some of the jobs
        fail.
    * ``"on_success_only"``: Submit "collect" task and run only if all jobs
        succeed.
    * ``"no"``: Do not submit "collect" task.

    """

    Yes = "yes"
    No = "no"
    OnSuccessOnly = "on_success_only"


class HTCondorAdapter(QueueContextAdapter):
    """Class for generating queueing scripts for HTCondor.

    Parameters
    ----------
    job_name : str
        The job name to be used by HTCondor.
    job_dir : pathlib.Path
        The path to the job directory.
    yaml_config_path : pathlib.Path
        The path to the YAML config file.
    elements : Elements
        Element(s) to process. Will be used to index the DataGrabber.
    pre_run_cmds : str or None, optional
        Extra shell commands to source before the run (default None).
    pre_collect_cmds : str or None, optional
        Extra shell commands to source before the collect (default None).
    env : :class:`.QueueContextEnv` or None, optional
        The environment configuration. If None, will run without a
        virtual environment of any kind (default None).
    verbose : str, optional
        The level of verbosity (default "info").
    verbose_datalad : str or None, optional
        The level of verbosity for datalad. If None, will be the same
        as ``verbose`` (default None).
    cpus : int, optional
        The number of CPU cores to use (default 1).
    mem : str, optional
        The size of memory (RAM) to use (default "8G").
    disk : str, optional
        The size of disk (HDD or SSD) to use (default "1G").
    extra_preamble : str or None, optional
        Extra commands to pass to HTCondor (default None).
    collect_task : :class:`.HTCondorCollect`, optional
        Whether to submit "collect" task for junifer (default "yes").
    submit : bool, optional
        Whether to submit the jobs. In any case, .dag files will be created
        for submission (default False).

    See Also
    --------
    QueueContextAdapter :
        The base class for QueueContext.
    GnuParallelLocalAdapter :
        The concrete class for queueing via GNU Parallel (local).

    """

    job_name: str
    job_dir: Path
    yaml_config_path: Path
    elements: Elements
    pre_run_cmds: Optional[str] = None
    pre_collect_cmds: Optional[str] = None
    env: Optional[QueueContextEnv] = None
    verbose: str = "info"
    verbose_datalad: Optional[str] = None
    cpus: int = 1
    mem: str = "8G"
    disk: str = "1G"
    extra_preamble: Optional[str] = None
    collect_task: HTCondorCollect = HTCondorCollect.Yes
    submit: bool = False

    def model_post_init(self, context: Any):  # noqa: D102
        if self.env is None:
            self.env = QueueContextEnv(
                kind=EnvKind.Local, shell=EnvShell.Bash, name=""
            )
        if self.env["kind"] == EnvKind.Local:
            # No virtual environment
            self._executable = "junifer"
            self._arguments = ""
        else:
            self._executable = f"run_{self.env['kind']}.{self.env['shell']}"
            self._arguments = f"{self.env['name']} junifer"
            self._exec_path = self.job_dir / self._executable
        self._log_dir = self.job_dir / "logs"
        self._pre_run_path = self.job_dir / "pre_run.sh"
        self._pre_collect_path = self.job_dir / "pre_collect.sh"
        self._submit_run_path = self.job_dir / f"run_{self.job_name}.submit"
        self._submit_collect_path = (
            self.job_dir / f"collect_{self.job_name}.submit"
        )
        self._dag_path = self.job_dir / f"{self.job_name}.dag"

    def pre_run(self) -> str:
        """Return pre-run commands."""
        fixed = (
            f"#!/usr/bin/env {self.env['shell']}\n\n"
            "# This script is auto-generated by junifer.\n\n"
            "# Force datalad to run in non-interactive mode\n"
            "DATALAD_UI_INTERACTIVE=false\n"
        )
        var = self.pre_run_cmds or ""
        return fixed + "\n" + var

    def run(self) -> str:
        """Return run commands."""
        verbose_args = f"--verbose {self.verbose} "
        if self.verbose_datalad is not None:
            verbose_args = (
                f"{verbose_args} --verbose-datalad {self.verbose_datalad} "
            )
        junifer_run_args = (
            "run "
            f"{self.yaml_config_path.resolve()!s} "
            f"{verbose_args}"
            "--element $(element)"
        )
        log_dir_prefix = (
            f"{self._log_dir.resolve()!s}/junifer_run_$(log_element)"
        )
        fixed = (
            "# This script is auto-generated by junifer.\n\n"
            "# Environment\n"
            "universe = vanilla\n"
            "getenv = True\n\n"
            "# Resources\n"
            f"request_cpus = {self.cpus}\n"
            f"request_memory = {self.mem}\n"
            f"request_disk = {self.disk}\n\n"
            "# Executable\n"
            f"initial_dir = {self.job_dir.resolve()!s}\n"
            f"executable = $(initial_dir)/{self._executable}\n"
            f"transfer_executable = False\n\n"
            f"arguments = {self._arguments} {junifer_run_args}\n\n"
            "# Logs\n"
            f"log = {log_dir_prefix}.log\n"
            f"output = {log_dir_prefix}.out\n"
            f"error = {log_dir_prefix}.err\n"
        )
        var = self.extra_preamble or ""
        return fixed + "\n" + var + "\n" + "queue"

    def pre_collect(self) -> str:
        """Return pre-collect commands."""
        fixed = (
            f"#!/usr/bin/env {self.env['shell']}\n\n"
            "# This script is auto-generated by junifer.\n"
        )
        var = self.pre_collect_cmds or ""
        # Add commands if collect="yes"
        if self.collect_task == "yes":
            var += 'if [ "${1}" == "4" ]; then\n    exit 1\nfi\n'
        return fixed + "\n" + var

    def collect(self) -> str:
        """Return collect commands."""
        verbose_args = f"--verbose {self.verbose} "
        if self.verbose_datalad is not None:
            verbose_args = (
                f"{verbose_args} --verbose-datalad {self.verbose_datalad} "
            )

        junifer_collect_args = (
            f"collect {self.yaml_config_path.resolve()!s} {verbose_args}"
        )
        log_dir_prefix = f"{self._log_dir.resolve()!s}/junifer_collect"
        fixed = (
            "# This script is auto-generated by junifer.\n\n"
            "# Environment\n"
            "universe = vanilla\n"
            "getenv = True\n\n"
            "# Resources\n"
            f"request_cpus = {self.cpus}\n"
            f"request_memory = {self.mem}\n"
            f"request_disk = {self.disk}\n\n"
            "# Executable\n"
            f"initial_dir = {self.job_dir.resolve()!s}\n"
            f"executable = $(initial_dir)/{self._executable}\n"
            "transfer_executable = False\n\n"
            f"arguments = {self._arguments} {junifer_collect_args}\n\n"
            "# Logs\n"
            f"log = {log_dir_prefix}.log\n"
            f"output = {log_dir_prefix}.out\n"
            f"error = {log_dir_prefix}.err\n"
        )
        var = self.extra_preamble or ""
        return fixed + "\n" + var + "\n" + "queue"

    def dag(self) -> str:
        """Return HTCondor DAG commands."""
        fixed = ""
        for idx, element in enumerate(self.elements):
            # Stringify elements if tuple for operation
            str_element = (
                ",".join(element) if isinstance(element, tuple) else element
            )
            # Stringify elements if tuple for logging
            log_element = (
                "-".join(element) if isinstance(element, tuple) else element
            )
            fixed += (
                f"JOB run{idx} {self._submit_run_path}\n"
                f'VARS run{idx} element="{str_element}" '  # needs to be
                f'log_element="{log_element}"\n\n'  # double quoted
            )
        var = ""
        if self.collect_task == "yes":
            var += (
                f"FINAL collect {self._submit_collect_path}\n"
                f"SCRIPT PRE collect {self._pre_collect_path.as_posix()} "
                "$DAG_STATUS\n"
            )
        elif self.collect_task == "on_success_only":
            var += f"JOB collect {self._submit_collect_path}\nPARENT "
            for idx, _ in enumerate(self.elements):
                var += f"run{idx} "
            var += "CHILD collect\n"

        return fixed + "\n" + var

    def prepare(self) -> None:
        """Prepare assets for submission."""
        logger.info("Creating HTCondor job")
        # Create logs
        logger.info(
            f"Creating logs directory under {self.job_dir.resolve()!s}"
        )
        self._log_dir.mkdir(exist_ok=True, parents=True)
        # Copy executable if not local
        if hasattr(self, "_exec_path"):
            logger.info(
                f"Copying {self._executable} to {self._exec_path.resolve()!s}"
            )
            shutil.copy(
                src=Path(__file__).parent.parent / "res" / self._executable,
                dst=self._exec_path,
            )
            make_executable(self._exec_path)
        # Create pre run
        logger.info(
            f"Writing {self._pre_run_path.name} to {self.job_dir.resolve()!s}"
        )
        self._pre_run_path.touch()
        self._pre_run_path.write_text(textwrap.dedent(self.pre_run()))
        make_executable(self._pre_run_path)
        # Create run
        logger.debug(
            f"Writing {self._submit_run_path.name} to "
            f"{self.job_dir.resolve()!s}"
        )
        self._submit_run_path.touch()
        self._submit_run_path.write_text(textwrap.dedent(self.run()))
        # Create pre collect
        logger.info(
            f"Writing {self._pre_collect_path.name} to "
            f"{self.job_dir.resolve()!s}"
        )
        self._pre_collect_path.touch()
        self._pre_collect_path.write_text(textwrap.dedent(self.pre_collect()))
        make_executable(self._pre_collect_path)
        # Create collect
        logger.debug(
            f"Writing {self._submit_collect_path.name} to "
            f"{self.job_dir.resolve()!s}"
        )
        self._submit_collect_path.touch()
        self._submit_collect_path.write_text(textwrap.dedent(self.collect()))
        # Create DAG
        logger.debug(
            f"Writing {self._dag_path.name} to {self.job_dir.resolve()!s}"
        )
        self._dag_path.touch()
        self._dag_path.write_text(textwrap.dedent(self.dag()))
        # Submit if required
        condor_submit_dag_cmd = [
            "condor_submit_dag",
            "-include_env HOME",
            f"{self._dag_path.resolve()!s}",
        ]
        if self.submit:
            run_ext_cmd(name="condor_submit_dag", cmd=condor_submit_dag_cmd)
        else:
            logger.info(
                f"HTCondor job files created, to submit the job, run:\n"
                f"{' '.join(condor_submit_dag_cmd)}"
            )
